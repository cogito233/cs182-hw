{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Cs5P34rU7rT",
        "outputId": "9d5cb256-c503-4142-ee07-9bfbebfa8ccb"
      },
      "outputs": [],
      "source": [
        "#@title install the openai GTP-3 API\n",
        "!pip install openai\n",
        "!pip install transformers\n",
        "!pip install inflect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCd-lD2jU7rX"
      },
      "outputs": [],
      "source": [
        "import pickle as pkl\n",
        "import os\n",
        "import json\n",
        "import openai\n",
        "import random\n",
        "import inflect\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle as pkl\n",
        "import torch\n",
        "from torch import nn\n",
        "random.seed(0)\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnghhJjYU7rY"
      },
      "source": [
        "# Load the dataset\n",
        "\n",
        "We will be using the Common Sense QA dataset, which is a collection of questions about everyday life. The cells below download the data from https://www.tau-nlp.sites.tau.ac.il/commonsenseqa ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9rldi5WU7rZ"
      },
      "outputs": [],
      "source": [
        "# Load dataset from jsonl file\n",
        "def make_dataset(path):\n",
        "    dataset = []\n",
        "    with open(path) as f:\n",
        "        for line in f:\n",
        "            dataset.append(json.loads(line))\n",
        "    return dataset        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLwUUEk3U7rZ",
        "outputId": "799b086d-7087-4e1b-d487-8c0477016c99"
      },
      "outputs": [],
      "source": [
        "#@title download the dataset\n",
        "!curl https://s3.amazonaws.com/commensenseqa/train_rand_split.jsonl -o train_rand_split.jsonl\n",
        "!curl https://s3.amazonaws.com/commensenseqa/dev_rand_split.jsonl -o dev_rand_split.jsonl\n",
        "!curl https://s3.amazonaws.com/commensenseqa/test_rand_split_no_answers.jsonl -o test_rand_split_no_answers.jsonl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhoOwcDYU7ra",
        "outputId": "8b1b0eb6-d809-4390-c6fe-f8069768961f"
      },
      "outputs": [],
      "source": [
        "train_set = make_dataset('train_rand_split.jsonl')\n",
        "val_set = make_dataset('dev_rand_split.jsonl')\n",
        "\n",
        "# Print the lengths of the train and validation sets\n",
        "print(len(train_set), len(val_set))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p02tkKfGU7ra"
      },
      "source": [
        "Here are a few examples of the dataset format:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "se1rOuGkU7rb",
        "outputId": "246141b3-f335-4dc8-84f1-b7b1a950a1f4"
      },
      "outputs": [],
      "source": [
        "val_set[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fUcl1PcU7rc"
      },
      "source": [
        "Make an OpenAI account, find your API key at https://beta.openai.com/account/api-keys, an paste it below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w258J--PU7rc"
      },
      "outputs": [],
      "source": [
        "# Set the api key\n",
        "openai.api_key = 'TODO: make an OpenAI account and paste your API key here'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWXXcazzU7rc"
      },
      "source": [
        "In this notebook, we'll explore different hard-prompting strategies. Run the cells below to see a few example strategies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2caC6yf4U7rd"
      },
      "outputs": [],
      "source": [
        "def make_simple_prompt(data_point):\n",
        "    prompt = f\"\"\"{data_point['question']['stem']}\n",
        " {data_point['question']['choices'][0]['label']} {data_point['question']['choices'][0]['text']}\n",
        " {data_point['question']['choices'][1]['label']} {data_point['question']['choices'][1]['text']}\n",
        " {data_point['question']['choices'][2]['label']} {data_point['question']['choices'][2]['text']}\n",
        " {data_point['question']['choices'][3]['label']} {data_point['question']['choices'][3]['text']}\n",
        " {data_point['question']['choices'][4]['label']} {data_point['question']['choices'][4]['text']}\n",
        "\"\"\"\n",
        "    return prompt\n",
        "\n",
        "def make_simple_qa_prompt(data_point):\n",
        "    prompt = f\"\"\"Question: {data_point['question']['stem']}\n",
        "Choice {data_point['question']['choices'][0]['label']}: {data_point['question']['choices'][0]['text']}\n",
        "Choice {data_point['question']['choices'][1]['label']}: {data_point['question']['choices'][1]['text']}\n",
        "Choice {data_point['question']['choices'][2]['label']}: {data_point['question']['choices'][2]['text']}\n",
        "Choice {data_point['question']['choices'][3]['label']}: {data_point['question']['choices'][3]['text']}\n",
        "Choice {data_point['question']['choices'][4]['label']}: {data_point['question']['choices'][4]['text']}\n",
        "Answer:\"\"\"\n",
        "    return prompt\n",
        "\n",
        "def get_instruction():\n",
        "    return \"Answer the following question with A, B, C, D, or E.\\n\"\n",
        "    \n",
        "def make_qa_instruction_prompt(data_point):\n",
        "    prompt = get_instruction()\n",
        "    prompt += make_simple_qa_prompt(data_point)\n",
        "    return prompt\n",
        "\n",
        "def make_few_shot_prompt(data_point, num_shots):\n",
        "    prompt = get_instruction()\n",
        "    for i in range(num_shots):\n",
        "        prompt += make_simple_qa_prompt(train_set[i])\n",
        "        prompt += f\" {train_set[i]['answerKey']}\\n\"\n",
        "    prompt += make_simple_qa_prompt(data_point)\n",
        "    return prompt\n",
        "\n",
        "# This is like the prompt above, but the answers in the examples given are random, not the correct answer\n",
        "def make_incorrect_few_shot_prompt(data_point, num_shots):\n",
        "    prompt = get_instruction()\n",
        "    for i in range(num_shots):\n",
        "        prompt += make_simple_prompt(train_set[i])\n",
        "        valid_answers = ['A', 'B', 'C', 'D', 'E']\n",
        "        valid_answers.remove(train_set[i]['answerKey'])\n",
        "        # Randomly choose an incorrect answer\n",
        "        random_answer = random.choice(valid_answers)\n",
        "        prompt += f\"{random_answer}\\n\"\n",
        "    prompt += make_simple_qa_prompt(data_point)\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrXbp2iMU7re",
        "outputId": "946e01d9-7a94-41bc-9aed-7a513b62f863"
      },
      "outputs": [],
      "source": [
        "# Print one example of each prompt type\n",
        "print('='*40, 'Simple Prompt', '='*40)\n",
        "print(make_simple_prompt(train_set[0]))\n",
        "print('='*40, 'Simple QA Prompt', '='*40)\n",
        "print(make_simple_qa_prompt(train_set[0]))\n",
        "print('='*40, 'QA Instruction Prompt', '='*40)\n",
        "print(make_qa_instruction_prompt(train_set[0]))\n",
        "print('='*40, 'Few Shot Prompt', '='*40)\n",
        "print(make_few_shot_prompt(train_set[8], 4))\n",
        "print('='*40, 'Incorrect Few Shot Prompt', '='*40)\n",
        "print(make_incorrect_few_shot_prompt(train_set[8], 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NxHU7rQU7re"
      },
      "source": [
        "# Running the model\n",
        "\n",
        "The cells below contain code to query the OpenAI's GPT-3 model. You can read more about the API here: https://beta.openai.com/docs/api-reference/completions/create.\n",
        "\n",
        "The algorithm is as follows:\n",
        "1. Format the multiple-choice question as a prompt such that the expected continuation is the answer to the question.\n",
        "2. Query the model with the prompt.\n",
        "3. Parse the model's response to extract the answer. (In this case, since the model's response is a single word, we just take the entire response.)\n",
        "\n",
        "\n",
        "If you run into rate limits, just wait a bit and retry. (Previous queries will stay in the cache, so you won't have to re-query them.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i87UtnWVU7rf"
      },
      "outputs": [],
      "source": [
        "# Parameters for the query. \n",
        "# Run with the defaults first, then if you want try changing them to see how it affects the results\n",
        "engine = \"text-davinci-002\"  # This is the biggest (and most expensive) model. You can also try \"text-babbage-001\" or \"text-curie-001\"\n",
        "temperature = 0.0 # Control randomness. For more randomness, set to a higher value. For QA, we recommend 0.0\n",
        "max_tokens = 1 # Only generate 1 token (the answer)\n",
        "logprobs = 5  # Return the probabilities for the top 5 choices (5 is the maximum possible with this api)\n",
        "\n",
        "def query_openai(prompt):\n",
        "    response = openai.Completion.create(\n",
        "      engine=engine,\n",
        "      prompt=prompt,\n",
        "      temperature=temperature,\n",
        "      max_tokens=max_tokens,\n",
        "      logprobs=logprobs,\n",
        "    )\n",
        "    return response\n",
        "  \n",
        "# We will store the results in a cache so we don't have to query OpenAI every time\n",
        "# This will avoid hitting the API rate limit and spending too much money\n",
        "cache = {}\n",
        "if os.path.exists('cache.pkl'):\n",
        "    with open('cache.pkl', 'rb') as f:\n",
        "        cache = pkl.load(f)\n",
        "\n",
        "# Return the log probability of the correct answer and the most probable answer\n",
        "def query_model(prompt, correct_answer):\n",
        "    # Check if the query is in the cache\n",
        "    inputs = (prompt, correct_answer, engine, temperature, max_tokens, logprobs)\n",
        "    if inputs in cache:\n",
        "        response = cache[inputs]\n",
        "    else:\n",
        "        response = query_openai(prompt)\n",
        "        cache[inputs] = response\n",
        "        # Save cache to file\n",
        "        with open('cache.pkl', 'wb') as f:\n",
        "            pkl.dump(cache, f)\n",
        "    log_probs = response['choices'][0]['logprobs']['top_logprobs'][0]\n",
        "        \n",
        "    most_probable = response['choices'][0]['text']\n",
        "    return log_probs, most_probable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6q2Q8Sf6U7rf"
      },
      "outputs": [],
      "source": [
        "# For simplicity (and to save time), we'll only use the first 10 data points\n",
        "# You can get more reliable results by using more data points, but you will\n",
        "# expend your free credits faster and will hit the API rate limit more quickly\n",
        "num_points = 10\n",
        "mini_train = val_set[:num_points]\n",
        "num_shots = 4\n",
        "\n",
        "# Consider adding additional prompts of your own here.\n",
        "prompt_strategies = {\n",
        "    'simple': make_simple_prompt,\n",
        "    'simple_qa': make_simple_qa_prompt,\n",
        "    'qa_instruction': make_qa_instruction_prompt,\n",
        "    'few_shot': lambda x: make_few_shot_prompt(x, num_shots),\n",
        "    'incorrect_few_shot': lambda x: make_incorrect_few_shot_prompt(x, num_shots)\n",
        "}\n",
        "\n",
        "def compute_acc(data_points, prompt_strategy):\n",
        "    accuracies = []\n",
        "    valid_responses = []\n",
        "    for data_point in data_points:\n",
        "        print(f'Question: {data_point[\"question\"][\"stem\"]}, Answer: {data_point[\"answerKey\"]}, Choices: {[choice[\"text\"] for choice in data_point[\"question\"][\"choices\"]]}')\n",
        "        prompt = prompt_strategy(data_point)\n",
        "        correct_answer = f' {data_point[\"answerKey\"]}'\n",
        "        \n",
        "        log_probs, most_probable = query_model(prompt, correct_answer)\n",
        "        accuracies += [int(most_probable == correct_answer)]\n",
        "        valid_responses += [most_probable in [' A', ' B', ' C', ' D', ' E']]\n",
        "        print(f'   LM predicted |{most_probable}|, accuracy: {accuracies[-1]}')\n",
        "    return np.mean(accuracies), np.mean(valid_responses)\n",
        "\n",
        "def plot_all_accs(data_points, prompt_strategies):\n",
        "    accuracies = []\n",
        "    valid_responses = []\n",
        "    for prompt_name, prompt_strategy in prompt_strategies.items():\n",
        "        accuracy, valid_rate = compute_acc(data_points, prompt_strategy)\n",
        "        accuracies += [accuracy]\n",
        "        valid_responses += [valid_rate]\n",
        "    # Plot a bar chart of the accuracies\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.bar(prompt_strategies.keys(), accuracies)\n",
        "    plt.title('Accuracies')\n",
        "    plt.show()\n",
        "    # Plot a bar chart of the valid responses\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.bar(prompt_strategies.keys(), valid_responses)\n",
        "    plt.title('Valid Responses')\n",
        "    plt.show()\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlZ9rNdCU7rg"
      },
      "outputs": [],
      "source": [
        "plot_all_accs(mini_train, prompt_strategies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ic7JH8WTU7rg"
      },
      "source": [
        "# Analysis\n",
        "\n",
        "TODO: in the cells below, implement code to analyze the model's performance.\n",
        "* What kinds of failures do you see with different prompting strategies?\n",
        "* Does providing correct labels in few-shot prompting have a significant impact on accuracy?\n",
        "* Observe the model’s log probabilities. Does it seem more confident when it is correct than when it is incorrect?\n",
        "\n",
        "A function to plot the model's confidence has been implemented for you, but you should feel free to write code to do additional analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "BWnuRosfU7rg",
        "outputId": "0bba6ce7-db01-418e-af5b-17da60aca298"
      },
      "outputs": [],
      "source": [
        "# Printing the log probs for the generated tokens\n",
        "prompt_strategies = {\n",
        "    # 'simple': make_simple_prompt, # removed since it's always incorrect\n",
        "    'simple_qa': make_simple_qa_prompt,\n",
        "    'qa_instruction': make_qa_instruction_prompt,\n",
        "    'few_shot': lambda x: make_few_shot_prompt(x, num_shots),\n",
        "    'incorrect_few_shot': lambda x: make_incorrect_few_shot_prompt(x, num_shots)\n",
        "}\n",
        "\n",
        "argmax_lp_correct = []\n",
        "argmax_lp_incorrect = []\n",
        "for prompt_name, prompt_strategy in prompt_strategies.items():\n",
        "    argmax_lp_correct_prompt = []\n",
        "    argmax_lp_incorrect_prompt = []\n",
        "    for data_point in val_set[:num_points]:\n",
        "        prompt = prompt_strategy(data_point)\n",
        "        correct_answer = f' {data_point[\"answerKey\"]}'\n",
        "        \n",
        "        log_probs, most_probable = query_model(prompt, correct_answer)        \n",
        "        log_prob_argmax = log_probs[most_probable]\n",
        "        if most_probable == correct_answer:\n",
        "            argmax_lp_correct_prompt += [log_prob_argmax]\n",
        "        else:\n",
        "            argmax_lp_incorrect_prompt += [log_prob_argmax]\n",
        "            \n",
        "    argmax_lp_correct += [np.mean(argmax_lp_correct_prompt)]\n",
        "    argmax_lp_incorrect += [np.mean(argmax_lp_incorrect_prompt)]\n",
        "    \n",
        "# Plot a bar chart of the accuracies. The bar chart has two bars for each prompt strategy.\n",
        "# These bars are placed side by side, so you can compare the accuracies of the two strategies.\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(np.arange(len(prompt_strategies)) - 0.2, np.exp(argmax_lp_correct), width=0.4, label='Correct')\n",
        "plt.bar(np.arange(len(prompt_strategies)) + 0.2, np.exp(argmax_lp_incorrect), width=0.4, label='Incorrect')\n",
        "plt.title('Confidence (Probability of most likely token)')\n",
        "plt.xticks(np.arange(len(prompt_strategies)), prompt_strategies.keys())\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z16OJFJfU7rh"
      },
      "source": [
        "# Training GPT-2 for soft prompt tuning\n",
        "\n",
        "GPT-2 is the smaller predecessor model to GPT-3. We will use GPT-2 for soft prompt tuning as it is\n",
        "publicly available(unlike GPT-3) and small enough to train on the free version of the colab GPU \n",
        "(unlike GPT-J).\n",
        "\n",
        "Soft prompt tuning is described in this [paper](https://arxiv.org/abs/2104.08691v1), which we encourage you to learn more about. In essence, instead of generating answers by putting in token prompts, we use fine tuning to train the embeddings of new learned tokens. This allows us to generate answers by putting in the new learned tokens instead of tokens which correspond to real words.\n",
        "\n",
        "Most of the code has been implemented for you, but you should still read through the code to understand what it's doing. There is one TODO which asks you to set up the optimizer. Think about which parameters should get passed into the optimizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKSHHwAXU7rh"
      },
      "outputs": [],
      "source": [
        "#@title Define soft embedding for GPT-2\n",
        "#@markdown code adapted from [this github repo](https://github.com/kipgparker/soft-prompt-tuning) implementing the [soft prompt tuning paper](https://arxiv.org/abs/2104.08691v1) \n",
        "class SoftEmbedding(nn.Module):\n",
        "    def __init__(self, \n",
        "                wte: nn.Embedding,\n",
        "                n_tokens: int = 10, \n",
        "                random_range: float = 0.5,\n",
        "                initialize_from_vocab: bool = True):\n",
        "        \"\"\"\n",
        "        Here, we concatentate a new task-specific learned embedding to the existing GPT-2 embedding.\n",
        "        Args:\n",
        "            wte (nn.Embedding): original transformer word embedding\n",
        "            n_tokens (int, optional): number of tokens for task. Defaults to 10.\n",
        "            random_range (float, optional): range to init embedding (if not initialize from vocab). Defaults to 0.5.\n",
        "            initialize_from_vocab (bool, optional): initalizes from default vocab. Defaults to True.\n",
        "        \"\"\"\n",
        "        super(SoftEmbedding, self).__init__()\n",
        "        self.wte = wte\n",
        "        self.n_tokens = n_tokens\n",
        "        self.learned_embedding = nn.parameter.Parameter(self.initialize_embedding(wte,\n",
        "                                                                               n_tokens, \n",
        "                                                                               random_range, \n",
        "                                                                               initialize_from_vocab))\n",
        "            \n",
        "    def initialize_embedding(self, \n",
        "                             wte: nn.Embedding,\n",
        "                             n_tokens: int = 10, \n",
        "                             random_range: float = 0.5, \n",
        "                             initialize_from_vocab: bool = True):\n",
        "        \"\"\"initializes learned embedding\n",
        "        Args:\n",
        "            same as __init__\n",
        "        Returns:\n",
        "            torch.float: initialized using original schemes\n",
        "        \"\"\"\n",
        "        if initialize_from_vocab:\n",
        "            return self.wte.weight[:n_tokens].clone().detach()\n",
        "        return torch.FloatTensor(n_tokens, wte.weight.size(1)).uniform_(-random_range, random_range)\n",
        "            \n",
        "    def forward(self, tokens):\n",
        "        \"\"\"run forward pass\n",
        "        Args:\n",
        "            tokens (torch.long): input tokens before encoding\n",
        "        Returns:\n",
        "            torch.float: encoding of text concatenated with learned task specifc embedding\n",
        "        \"\"\"\n",
        "        # The first n_tokens embeddings are reserved for the learned embeddings\n",
        "        # The rest of the embeddings are the original GPT-2 embeddings\n",
        "        input_embedding = self.wte(tokens[:, self.n_tokens:])\n",
        "        learned_embedding = self.learned_embedding.repeat(input_embedding.size(0), 1, 1)\n",
        "        return torch.cat([learned_embedding, input_embedding], 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TWAX7kEU7ri",
        "outputId": "ea33fa80-2f6a-4586-960a-88a61c79377a"
      },
      "outputs": [],
      "source": [
        "#@markdown Set up a soft embedding version of GPT-2\n",
        "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\", padding_side='left')\n",
        "tokenizer.pad_token=tokenizer.eos_token\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_tokens = 100\n",
        "\n",
        "def initialize_soft_model():\n",
        "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "    \n",
        "    initialize_from_vocab = True\n",
        "\n",
        "    # Set the input embeddings to the GPT2 model\n",
        "    s_wte = SoftEmbedding(model.get_input_embeddings(), \n",
        "                        n_tokens=n_tokens, \n",
        "                        initialize_from_vocab=initialize_from_vocab)\n",
        "    model.set_input_embeddings(s_wte)\n",
        "    model.to(device)\n",
        "    return model\n",
        "\n",
        "# While we didn't need to do this for GPT-3 earlier, training the model means we need to turn the text \n",
        "# into tokens that the model can understand via the embedding layer.\n",
        "def process_dataset(dataset, mapper_fn, pad_length=119):\n",
        "    mapped_dataset = [mapper_fn(item) for item in dataset]\n",
        "    if pad_length is None:\n",
        "        out = tokenizer(mapped_dataset, return_tensors='pt', padding=True)\n",
        "    else:\n",
        "        out = tokenizer(mapped_dataset, return_tensors='pt', padding=\"max_length\", max_length=pad_length)\n",
        "    # Need to add a space as GPT differentiates between \" A\" and \"A\" and it will be predicting \" A\". \n",
        "    answerkey = [' ' + item['answerKey'] for item in dataset]\n",
        "    out['answerkey'] = tokenizer(answerkey, return_tensors='pt', max_length=1)['input_ids']\n",
        "    return out\n",
        "\n",
        "def pad_soft_inputs(inputs):\n",
        "    \"\"\"\n",
        "    We need to pad the attention_mask and input_ids with an extra n_learned_tokens\n",
        "    It does not matter what you pad input_ids with since these will be overwritten by learned embeddings\n",
        "    \"\"\"\n",
        "    batch = len(inputs['input_ids'])\n",
        "    inputs['input_ids'] = torch.cat([torch.full((batch, n_tokens), 50256).to(device), inputs['input_ids'].to(device)], 1).to(device)\n",
        "    inputs['attention_mask'] = torch.cat([torch.full((batch, n_tokens), 1).to(device), inputs['attention_mask'].to(device)], 1).to(device)\n",
        "    return inputs\n",
        "\n",
        "# Train the model\n",
        "def train_model(model, train_set, val_set, dataset_processor, batch_size=8, epochs=1, lr=1e-4, print_every=100):\n",
        "    train_dataset = process_dataset(train_set, dataset_processor)\n",
        "    val_dataset = process_dataset(val_set, dataset_processor)\n",
        "    parameters_to_train = # TODO\n",
        "    optimizer = torch.optim.Adam(parameters_to_train, lr=1e-4)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    epoch_train_losses = []\n",
        "    for i in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        for j in range(0, len(train_dataset['input_ids']), batch_size):\n",
        "            # Calculate cross entropy loss between predicted last token and actual last token\n",
        "            optimizer.zero_grad()\n",
        "            inputs = {k: v[j:j+batch_size].to(device) for k, v in train_dataset.items()}\n",
        "            inputs = pad_soft_inputs(inputs)\n",
        "            labels = inputs.pop('answerkey')\n",
        "            outputs = model(**inputs).logits[:, -1, :] # (batch_size, vocab_size)\n",
        "            loss = criterion(outputs, labels.squeeze())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # loss calculated by criterion is averaged over batch, so multiply by batch size to get total loss\n",
        "            epoch_loss += loss.item() * labels.shape[0]\n",
        "            if j % print_every == 0:\n",
        "                print(f'Epoch {i}, Item {j}, loss: {loss.item()}')\n",
        "        epoch_loss /= train_dataset['input_ids'].shape[0]\n",
        "        epoch_train_losses.append(epoch_loss)\n",
        "\n",
        "        # Evaluate on validation set\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        for j in range(0, len(val_dataset['input_ids']), batch_size):\n",
        "            inputs = {k: v[j:j+batch_size].to(device) for k, v in val_dataset.items()}\n",
        "            inputs = pad_soft_inputs(inputs)\n",
        "            labels = inputs.pop('answerkey')\n",
        "            outputs = model(**inputs).logits[:, -1, :]\n",
        "            if j == 0: print(f'decoding {tokenizer.decode(outputs.argmax(dim=-1))}')\n",
        "            loss = criterion(outputs, labels.squeeze())\n",
        "            val_loss += loss.item() * labels.shape[0]\n",
        "        val_loss /= val_dataset['input_ids'].shape[0]\n",
        "        print('-'*20)\n",
        "        print(f'Epoch {i}, Validation loss: {val_loss}')\n",
        "\n",
        "\n",
        "# This function lets us sample the next token (or, in our case, the next answer) from the model.\n",
        "def generate_output(model, inputs, pad_soft=True):\n",
        "    \"\"\" \n",
        "    Given a string text or a tokenized input (or list of these, if batched), returns the model's prediction for the\n",
        "    next token in the sequence.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    if type(inputs) is str or type(inputs) is list and type(inputs[0]) is str:\n",
        "        inputs = tokenizer(inputs, return_tensors=\"pt\").to(device)\n",
        "        \n",
        "    if pad_soft:\n",
        "        inputs = pad_soft_inputs(inputs)\n",
        "    outputs = model(**inputs).logits[0, -1, :]\n",
        "    outputs = outputs.argmax(dim=-1)\n",
        "    return tokenizer.decode(outputs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = initialize_soft_model()\n",
        "hard_embedding_model = GPT2LMHeadModel.from_pretrained('gpt2').to(device)\n",
        "print(generate_output(hard_embedding_model, 'Deep learning is an', pad_soft=False))\n",
        "\n",
        "# Print out the embeddings so you can see their shpaes\n",
        "print('Embedding object', model.get_input_embeddings())\n",
        "print('Learned embeddings', model.get_input_embeddings().learned_embedding.shape)\n",
        "print('Original vocab embeddings', model.get_input_embeddings().wte.weight.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCZQZU17XuJi",
        "outputId": "d99a7781-f825-47eb-ff48-a0f5d9484164"
      },
      "outputs": [],
      "source": [
        "prompt_strategy = 'qa_instruction'\n",
        "if prompt_strategy not in prompt_strategies:\n",
        "    print('prompt strategy must be one of', [i for i in prompt_strategies])\n",
        "else:\n",
        "    prompt_strategy = prompt_strategies[prompt_strategy]\n",
        "    train_model(model, train_set, val_set, prompt_strategy, batch_size=8, epochs=2) # you can reduce the batch size if you run out of memory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the model to a pickle file (If your runtime crashes, you can load the model from this file)\n",
        "with open('soft_embeddings_model_qa.pkl', 'wb') as f:\n",
        "    pkl.dump(model, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compare the performance of the model with hard prompting and with soft prompt tuning. If your implementation is correct, you should get around 21% correct and 0% invalid with the soft prompt. Answer the analysis questions in the written portion of the assignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3J3PS-70U7rj",
        "outputId": "7177c3b6-8b11-4101-a58a-dfb89ebf03b7"
      },
      "outputs": [],
      "source": [
        "#@title Let's compare a few examples from our prompts\n",
        "def compare_models(model1, model1_pad_soft, model2, model2_pad_soft, dataset, dataset_processor, n_entries=5):\n",
        "    processed_set = process_dataset(dataset, dataset_processor)\n",
        "    for i in range(n_entries):\n",
        "        data_point_idx = np.random.choice(len(dataset))\n",
        "        point = dataset[data_point_idx]\n",
        "        processed_point = processed_set[data_point_idx]\n",
        "        prompt = dataset_processor(point)\n",
        "        print(prompt)\n",
        "        output1 = generate_output(model1, dataset_processor(point), pad_soft=model1_pad_soft)\n",
        "        output2 = generate_output(model2, dataset_processor(point), pad_soft=model2_pad_soft)\n",
        "        print(f'gt: {point[\"answerKey\"]}. model1: {repr(output1)}. model2: {repr(output2)}')\n",
        "        print('-' * 20)\n",
        "\n",
        "\n",
        "compare_models(model, True, hard_embedding_model, False, val_set, prompt_strategy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfXUEeJmU7rj"
      },
      "outputs": [],
      "source": [
        "#@title Bar plot the distribution of incorrect answers, invalid answers, and correct answers\n",
        "def get_answer_stats(model, dataset, dataset_processor, verbose, pad_soft):\n",
        "    processed_set = process_dataset(dataset, dataset_processor)\n",
        "    correct = 0\n",
        "    incorrect = 0\n",
        "    invalid = 0\n",
        "    for i in range(len(dataset)):\n",
        "        inputs = {k: v[i:i+1].to(device) for k, v in processed_set.items()}\n",
        "        point = dataset[i]\n",
        "        prompt = dataset_processor(point)\n",
        "        label = inputs.pop('answerkey')\n",
        "        output = generate_output(model, inputs, pad_soft).strip()\n",
        "        if verbose: print(f'Prompt: {prompt}, output: |{output}|, answerkey |{point[\"answerKey\"]}|')\n",
        "        if output == point[\"answerKey\"]:\n",
        "            correct += 1\n",
        "        elif output in ['A', 'B', 'C', 'D', 'E'] or not point['answerKey'] in ['A', 'B', 'C', 'D', 'E']:\n",
        "            incorrect += 1\n",
        "        else:\n",
        "            invalid += 1\n",
        "    correct, incorrect, invalid = correct/len(dataset), incorrect/len(dataset), invalid/len(dataset)\n",
        "    return correct, incorrect, invalid\n",
        "\n",
        "def plot_answer_stats(model, dataset, dataset_processor, verbose=False, pad_soft=True):\n",
        "    correct, incorrect, invalid = get_answer_stats(model, dataset, dataset_processor, verbose, pad_soft)\n",
        "    plt.bar(['correct', 'incorrect', 'invalid'], [correct, incorrect, invalid])\n",
        "    plt.title('Answer distribution')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "4F-l72jcU7rj",
        "outputId": "49443081-0876-4794-da38-14dd6d71bd2c"
      },
      "outputs": [],
      "source": [
        "plot_answer_stats(model, val_set, prompt_strategy, verbose=True, pad_soft=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "5ZY_SuePeBK4",
        "outputId": "afdc0efb-9889-4137-cea4-435047bd7dbd"
      },
      "outputs": [],
      "source": [
        "plot_answer_stats(hard_embedding_model, val_set, prompt_strategies['qa_instruction'], pad_soft=False, verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_soft_qa = model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pluralize task\n",
        "\n",
        "As you can see above, the soft embedding model does not perform very well on this task. We'll show how soft prompting does better on a second, very simple task - pluralizing a word.\n",
        "\n",
        "The dataset we use was found here, and consists of a list of English nouns: https://www.kaggle.com/datasets/leite0407/list-of-nouns?select=nounlist.csv. \n",
        "For simplicity, we will only consider words where the output is a single token (to avoid needing to deal with sequential generation for evaluation), but you could adapt the code to generate arbitrarily long outputs.\n",
        "\n",
        "If you get memory errors when running this part, re-run the notebook while skipping loading the previous dataset and soft model.\n",
        "\n",
        "\n",
        "!! If you run into an error during training complaining about batch size dimensions, this is an edge-case issue where we get errors when the last batch in an epoch length 1. You can fix this by removing the item in the train set. !!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!curl https://inst.eecs.berkeley.edu/~cs182/fa22/assets/assignments/nounlist.csv -o nounlist.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll create targets for this dataset using the inflect library, which is a Python library for inflecting English words. You can read more about it here: https://pypi.org/project/inflect/. This library can convert word to plural forms (though it is not 100% reliable)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2gUrggh_XAl"
      },
      "outputs": [],
      "source": [
        "# Set of words with unusual plurals\n",
        "noun_test = ['foot', 'man', 'person', 'self', 'wife', 'wolf', 'woman']\n",
        "\n",
        "engine = inflect.engine()\n",
        "\n",
        "# Load new noun_list dataset from csv file\n",
        "with open('nounlist.csv', 'r') as f:\n",
        "    noun_list = f.read().splitlines()\n",
        "    noun_list = [i.strip() for i in noun_list]\n",
        "random.seed(0)\n",
        "# shuffle the noun list\n",
        "random.shuffle(noun_list)\n",
        "# Remove all list items which are in the nouns list (our test set)\n",
        "noun_list = [i for i in noun_list if i not in noun_test]\n",
        "# Remove the last 10% for validation\n",
        "noun_train = noun_list[:-int(len(noun_list)*0.1)]\n",
        "noun_val = noun_list[-int(len(noun_list)*0.1):]\n",
        "\n",
        "# Plural task\n",
        "def format_dataset(noun_list):\n",
        "    dataset = []\n",
        "    for noun in noun_list:\n",
        "        plural = engine.plural(noun)\n",
        "        dataset.append({'answerKey': plural, 'input': noun})\n",
        "    return dataset\n",
        "\n",
        "\n",
        "noun_train = format_dataset(noun_train)\n",
        "noun_val = format_dataset(noun_val)\n",
        "noun_test = format_dataset(noun_test)\n",
        "\n",
        "\n",
        "# Only include nouns where the plural is a single token\n",
        "noun_train = [i for i in noun_train if len(tokenizer(i['answerKey'])['input_ids']) == 1]\n",
        "noun_val = [i for i in noun_val if len(tokenizer(i['answerKey'])['input_ids']) == 1]\n",
        "noun_test = [i for i in noun_test if len(tokenizer(i['answerKey'])['input_ids']) == 1]\n",
        "\n",
        "# Print the first 10 items in the dataset\n",
        "print([point['input'] for point in noun_train[:10]])\n",
        "print([point['answerKey'] for point in noun_train[:10]])\n",
        "\n",
        "print(f'Lengths: train: {len(noun_train)}, val: {len(noun_val)}, test: {len(noun_test)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compare hard prompting with soft prompting on this task, then answer the analysis questions in the written part of this homework. You should get over 60% correct on the val set with soft prompting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def basic_format(point):\n",
        "    if isinstance(point, dict):\n",
        "        point = point['input']\n",
        "    return f\"The plural of {point} is\"\n",
        "\n",
        "examples = ['pasta', 'sweater', 'wave', 'mouse', 'attorney', 'bottle', 'phone', 'grass', 'evening', 'candy', 'flower', 'planet', 'architect', 'washer',\n",
        "            'keyhole', 'economy', 'grace', 'finance', 'midnight', 'cushion', 'plateau', 'mouse', 'chord', 'cactus', 'swap', 'tremor', 'criterion', 'sink', 'bandana', 'trade'\n",
        "            ]\n",
        "\n",
        "def make_few_shot(i):\n",
        "    def few_shot(point):\n",
        "        prompt = ''\n",
        "        for j in range(i):\n",
        "            prompt += basic_format(examples[j]) + ' ' + engine.plural(examples[j]) + '.\\n'\n",
        "        prompt += basic_format(point)\n",
        "        return prompt\n",
        "    return few_shot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_pluralize = initialize_soft_model()\n",
        "train_model(model_pluralize, noun_train, noun_val, basic_format, batch_size=8, epochs=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the model to a pickle file (If your runtime crashes, you can load the model from this file)\n",
        "with open('soft_embeddings_model_pluralize.pkl', 'wb') as f:\n",
        "    pkl.dump(model, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_answer_stats(model_pluralize, noun_val, basic_format, verbose=True, pad_soft=True)\n",
        "plot_answer_stats(model_pluralize, noun_test, basic_format, verbose=True, pad_soft=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot results with hard prompts of various lengths\n",
        "for num_shots in range(10):\n",
        "    plot_answer_stats(hard_embedding_model, noun_val, make_few_shot(num_shots), verbose=False, pad_soft=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deliverables\n",
        "\n",
        "Please submit this completed notebook and complete all the written questions."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.7.13 ('cs182_hw88')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "24c732284262cd41d749de7c2ab26fba11a555a98d922bf877eca389ddd668a1"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02536cab0cc045f5b3e2e41d967b63e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "129e1a6b95ff4148891d51738c2e56cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23e06b8635054b62b6b59c5e94bc7be9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e46eb727bfa6461691304a817a922ca6",
            "placeholder": "​",
            "style": "IPY_MODEL_2908ef4673a848f6a100253dc26bb12d",
            "value": "Downloading: 100%"
          }
        },
        "2908ef4673a848f6a100253dc26bb12d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cc995124dd64ab08f94a51ece62c71a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e4803a7de3c4c4b8863d813759c1e17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f15ec8589b04f2587c67701d28ba8b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cc995124dd64ab08f94a51ece62c71a",
            "placeholder": "​",
            "style": "IPY_MODEL_d5f34e52785f4378bd382fe36053c7c8",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 2.73MB/s]"
          }
        },
        "361cfa96247d4365836c75ac2f451c2d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d9b7ce38384424387c066cfb3ddfb76": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "488a2bb946d24269ad12634d69dbfbf8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b03cb66f79e49938024b8d9ccb4d2e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d58f54400c9c4b27a8f55635450bc573",
              "IPY_MODEL_8f923a102af941b9a52458a2cb555dfb",
              "IPY_MODEL_2f15ec8589b04f2587c67701d28ba8b1"
            ],
            "layout": "IPY_MODEL_66be9e9169384fe392ee67c7073e3f48"
          }
        },
        "4b6ee68d2e5f407288f3844c83056ae6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c42eb209a464aa893024bc32e188cd7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d5916006010476f9bddd063101c9cc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_488a2bb946d24269ad12634d69dbfbf8",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c3da43075be43689f0a651ea6df34e9",
            "value": 1042301
          }
        },
        "4fd404799bef4e7c996643e541658dc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3e7a311e4194a9b9f40585c16a1d6e2",
            "placeholder": "​",
            "style": "IPY_MODEL_a1f9f9dba69c4c24ab73003260607ea1",
            "value": " 456k/456k [00:00&lt;00:00, 934kB/s]"
          }
        },
        "50ef2b3486284e6cb53f0d1587f3f17e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53494b332c6b41f481d35becc9159caa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54b9443c8d1f4f3b87c83542f6e123ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2ab54bbedf940e5afca066d3fca0abf",
            "placeholder": "​",
            "style": "IPY_MODEL_02536cab0cc045f5b3e2e41d967b63e9",
            "value": "Downloading: 100%"
          }
        },
        "5b28919c1acd47c9a6e6d99adad1e328": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_361cfa96247d4365836c75ac2f451c2d",
            "max": 548118077,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ceff346e84d4b6f9da276b5cd6656e3",
            "value": 548118077
          }
        },
        "5c4e3edaaca64d2080405180e422a935": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eecc24314e7f4c0dac364792a387fd02",
              "IPY_MODEL_8e30043d0d08401282fec21a877e91e8",
              "IPY_MODEL_4fd404799bef4e7c996643e541658dc0"
            ],
            "layout": "IPY_MODEL_53494b332c6b41f481d35becc9159caa"
          }
        },
        "60ed4cc2af05446d893923a3f29d0f8e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66be9e9169384fe392ee67c7073e3f48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d7a55f8fb4e4d118bd58c892240f3ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7bcf6612dfb42fd88835a02676634c4",
            "placeholder": "​",
            "style": "IPY_MODEL_ea514c3b3f164992a2cf0849e49afa3c",
            "value": " 665/665 [00:00&lt;00:00, 21.3kB/s]"
          }
        },
        "6eb4c89fa88345cdb790465ae441a211": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ceff346e84d4b6f9da276b5cd6656e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e30043d0d08401282fec21a877e91e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c42eb209a464aa893024bc32e188cd7",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96c043772eea48fd9cddc0629173068f",
            "value": 456318
          }
        },
        "8f923a102af941b9a52458a2cb555dfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d9b7ce38384424387c066cfb3ddfb76",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc26e21d0f6a461a949564c23586e7b2",
            "value": 1355256
          }
        },
        "96c043772eea48fd9cddc0629173068f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b5377d590a446128ad6bb910b17cad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c3da43075be43689f0a651ea6df34e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ce33c7ab72c4911ac69d31c4bef883a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_129e1a6b95ff4148891d51738c2e56cf",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f29d67e90aa44e994f9b63dabb3e995",
            "value": 665
          }
        },
        "9f29d67e90aa44e994f9b63dabb3e995": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a1f9f9dba69c4c24ab73003260607ea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2ab54bbedf940e5afca066d3fca0abf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3e7a311e4194a9b9f40585c16a1d6e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a53e615568e2427ba749c3ef812db26f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6763b9683904fbe964713e4a802bb8c",
              "IPY_MODEL_4d5916006010476f9bddd063101c9cc2",
              "IPY_MODEL_bae6177a857f44c789106e9a33ea9ec4"
            ],
            "layout": "IPY_MODEL_c1e755c051724b2db633247a20c4fc83"
          }
        },
        "bae6177a857f44c789106e9a33ea9ec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0961c89ad7247a09c53301a7a15c273",
            "placeholder": "​",
            "style": "IPY_MODEL_9b5377d590a446128ad6bb910b17cad3",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 2.67MB/s]"
          }
        },
        "bc26e21d0f6a461a949564c23586e7b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c07fdfb512d3473aaaa6e18c252a2261": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_54b9443c8d1f4f3b87c83542f6e123ec",
              "IPY_MODEL_9ce33c7ab72c4911ac69d31c4bef883a",
              "IPY_MODEL_6d7a55f8fb4e4d118bd58c892240f3ca"
            ],
            "layout": "IPY_MODEL_60ed4cc2af05446d893923a3f29d0f8e"
          }
        },
        "c1e755c051724b2db633247a20c4fc83": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c37204871bab4fc191a972d85b5cf561": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d08ab574582f469f8b8ca478641c017e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2f529bf06c94624b0b3e81fe1403943": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d58f54400c9c4b27a8f55635450bc573": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c37204871bab4fc191a972d85b5cf561",
            "placeholder": "​",
            "style": "IPY_MODEL_50ef2b3486284e6cb53f0d1587f3f17e",
            "value": "Downloading: 100%"
          }
        },
        "d5f34e52785f4378bd382fe36053c7c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e46eb727bfa6461691304a817a922ca6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6763b9683904fbe964713e4a802bb8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea9dfc664de24cd396674b38227f80ef",
            "placeholder": "​",
            "style": "IPY_MODEL_6eb4c89fa88345cdb790465ae441a211",
            "value": "Downloading: 100%"
          }
        },
        "e7bcf6612dfb42fd88835a02676634c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e98279c60e3944139cdf55fbcee36d7b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea514c3b3f164992a2cf0849e49afa3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea9dfc664de24cd396674b38227f80ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eecc24314e7f4c0dac364792a387fd02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b6ee68d2e5f407288f3844c83056ae6",
            "placeholder": "​",
            "style": "IPY_MODEL_d2f529bf06c94624b0b3e81fe1403943",
            "value": "Downloading: 100%"
          }
        },
        "f068f97d9d19473081624aad4912a75b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23e06b8635054b62b6b59c5e94bc7be9",
              "IPY_MODEL_5b28919c1acd47c9a6e6d99adad1e328",
              "IPY_MODEL_f241d369fe724cc9adefc7f840650997"
            ],
            "layout": "IPY_MODEL_2e4803a7de3c4c4b8863d813759c1e17"
          }
        },
        "f0961c89ad7247a09c53301a7a15c273": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f241d369fe724cc9adefc7f840650997": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e98279c60e3944139cdf55fbcee36d7b",
            "placeholder": "​",
            "style": "IPY_MODEL_d08ab574582f469f8b8ca478641c017e",
            "value": " 548M/548M [00:09&lt;00:00, 58.6MB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
